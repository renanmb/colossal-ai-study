{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGqQS7B88YWI"
   },
   "source": [
    "# Environment Setup\n",
    "\n",
    "**[Caution]** this notebook can only be run with multiple GPUs due to parallelism settings. If you still want to run with one GPU, change config files to not use any parallelism explicitly.\n",
    "\n",
    "To run our examples smoothly, you need to have `conda` or `miniconda` installed on your device. Check out this [website](https://docs.conda.io/en/latest/miniconda.html) for more instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-85Gyad8Bo0",
    "outputId": "5260b8ff-0043-492e-9745-920a73005533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00-Start.ipynb\n",
      "01-Environment-Setup.ipynb\n",
      "02-Large-Scale-Optimizer.ipynb\n",
      "03-Hybrid-Parallelism.ipynb\n",
      "04-Sequence-Parallelism.ipynb\n",
      "05-Auto-Parallelism.ipynb\n",
      "06-OPT-Model-Inference.ipynb\n",
      "07-Fastfold-Inference.ipynb\n",
      "08-Stable-Diffusion-Inference.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls | grep ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2G2Fjdb_8Xa",
    "outputId": "710bdb4c-cd3a-41b8-e769-ee97c8896638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Installation Report ####\n",
      "\n",
      "------------ Environment ------------\n",
      "Colossal-AI version: 0.2.7\n",
      "PyTorch version: 1.12.1\n",
      "System CUDA version: 11.3\n",
      "CUDA version required by PyTorch: 11.3\n",
      "\n",
      "Note:\n",
      "1. The table above checks the versions of the libraries/tools in the current environment\n",
      "2. If the System CUDA version is N/A, you can set the CUDA_HOME environment variable to locate it\n",
      "3. If the CUDA version required by PyTorch is N/A, you probably did not install a CUDA-compatible PyTorch. This value is give by torch.version.cuda and you can go to https://pytorch.org/get-started/locally/ to download the correct version.\n",
      "\n",
      "------------ CUDA Extensions AOT Compilation ------------\n",
      "Found AOT CUDA Extension: ✓\n",
      "PyTorch version used for AOT compilation: N/A\n",
      "CUDA version used for AOT compilation: N/A\n",
      "\n",
      "Note:\n",
      "1. AOT (ahead-of-time) compilation of the CUDA kernels occurs during installation when the environment varialbe CUDA_EXT=1 is set\n",
      "2. If AOT compilation is not enabled, stay calm as the CUDA kernels can still be built during runtime\n",
      "\n",
      "------------ Compatibility ------------\n",
      "PyTorch version match: N/A\n",
      "System and PyTorch CUDA version match: ✓\n",
      "System and Colossal-AI CUDA version match: N/A\n",
      "\n",
      "Note:\n",
      "1. The table above checks the version compatibility of the libraries/tools in the current environment\n",
      "   - PyTorch version mistach: whether the PyTorch version in the current environment is compatible with the PyTorch version used for AOT compilation\n",
      "   - System and PyTorch CUDA version match: whether the CUDA version in the current environment is compatible with the CUDA version required by PyTorch\n",
      "   - System and Colossal-AI CUDA version match: whether the CUDA version in the current environment is compatible with the CUDA version used for AOT compilation\n"
     ]
    }
   ],
   "source": [
    "# Check versions of relevant packages\n",
    "!colossalai check -i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "933351abc630374ba7d69d29305d8827306c5eb75384e02fe79e055db4d99722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
